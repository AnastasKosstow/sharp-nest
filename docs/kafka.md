# SharpNest.Kafka

SharpNest.Kafka is a robust and flexible .NET library that simplifies Apache Kafka integration for your .NET applications.
<br>
It provides a clean abstraction over the Confluent.Kafka client with an intuitive API for publishing messages and consuming from topics.
<br>
With SharpNest.Kafka, you can easily implement resilient message handling with built-in retry strategies, automatic topic creation, and proper resource management.
<br>

Iùöù ùöúùöûùöôùöôùöòùöõùöùùöú ùöúùöíùöóùöêùöïùöéùöùùöòùöó, ùöúùöåùöòùöôùöéùöç, ùöäùöóùöç ùöùùöõùöäùöóùöúùöíùöéùöóùöù ùöïùöíùöèùöéùöùùöíùöñùöéùöú, ùöéùöóùöúùöûùöõùöíùöóùöê ùöôùöõùöòùöôùöéùöõ ùöçùöíùöúùöôùöòùöúùöäùöï ùöòùöè ùöîùöäùöèùöîùöä ùöåùöòùöóùöóùöéùöåùöùùöíùöòùöóùöú.

> [!IMPORTANT]
> Key Features:<br>
> &nbsp;&nbsp;&nbsp;‚úÖ Fluent Configuration API ‚Äì Configure Kafka settings in a readable, expressive manner.<br>
> &nbsp;&nbsp;&nbsp;‚úÖ Resilient Messaging ‚Äì Built-in retry strategies for handling transient failures.<br>
> &nbsp;&nbsp;&nbsp;‚úÖ Auto Topic Creation ‚Äì Topics are created automatically if they don't exist.<br>
> &nbsp;&nbsp;&nbsp;‚úÖ Proper Resource Management ‚Äì Ensures correct disposal of Kafka connections and resources.<br>
> &nbsp;&nbsp;&nbsp;‚úÖ Lifetime Control ‚Äì Supports Singleton, Scoped, and Transient service lifetimes.<br>
> &nbsp;&nbsp;&nbsp;‚úÖ Thread-Safe ‚Äì Ensures safe concurrent execution with proper synchronization.<br>

## üîß Installation

```bash
dotnet add package SharpNest.Kafka
```

## üõ†Ô∏è How to Register and Use SharpNest.Kafka

### 1Ô∏è‚É£ Add `SharpNest.Kafka` services

There are two ways to configure SharpNest.Kafka services:

üìå **Using configuration**
```cs
// Program.cs
using SharpNest.Kafka;

builder.Services
    .AddKafka(builder.Configuration)
    .AddPublisher()
    .AddSingletonSubscriber();
```

üìå **Using programmatic configuration**
```cs
services.AddKafka(options => 
{
    options.BootstrapServers = "localhost:9092";
    options.DefaultGroup = "my-consumer-group";
    options.Partitions = 3;
    options.ReplicationFactor = 2;
})
.AddPublisher()
.AddScopedSubscriber();
```

### 2Ô∏è‚É£ Configure Kafka Settings

Add the following to your `appsettings.json`:

```json
{
  "Kafka": {
    "BootstrapServers": "localhost:9092",
    "DefaultGroup": "default-group",
    "Partitions": 1,
    "ReplicationFactor": 1,
    "Subscriber": {
      "CommitEmptyMessages": true
    },
    "Publisher": {
      // Publisher-specific settings
    },
    "Security": {
      // Optional security settings
    }
  }
}
```

### 3Ô∏è‚É£ Publishing Messages

Inject the `IPublisher` interface to publish messages to Kafka:

```cs
public class MessageService(IPublisher publisher)
{
    private readonly IPublisher _publisher = publisher;

    ...
}
```

Simple message publishing
```cs
var result = await _publisher.PublishAsync(
    "my-topic",  // Topic name
    key,         // Message key
    content      // Message content
);
```

Publishing with custom headers
```cs
var headers = new KeyValuePair<string, byte[]>[] 
{ 
    new("content-type", Encoding.UTF8.GetBytes("application/json")),
    new("correlation-id", Encoding.UTF8.GetBytes(Guid.NewGuid().ToString()))
};

await _publisher.PublishAsync(
    "my-topic", 
    key, 
    content, 
    CancellationToken.None, 
    headers
);
```

Using KafkaMessage object
```cs
var message = new KafkaMessage
{
    Topic = "my-topic",
    Key = key,
    Value = content,
    Headers = new Dictionary<string, byte[]>
    {
        ["timestamp"] = Encoding.UTF8.GetBytes(DateTime.UtcNow.ToString("O"))
    }
};

await _publisher.PublishAsync(message);
```

### 4Ô∏è‚É£ Subscribing to Topics

#### üìå Single Service Subscription

```csharp
public class MessageConsumerService(ISubscriber subscriber, ILogger<MessageConsumerService> logger)
{
    private readonly ISubscriber _subscriber = subscriber;
    private readonly ILogger<MessageConsumerService> _logger = logger;
    
    public async Task StartConsumingAsync(CancellationToken cancellationToken)
    {
        await _subscriber.SubscribeAsync(
            "my-topic",
            async message => 
            {
                _logger.LogInformation(
                    "Received message: Key={Key}, Value={Value}", 
                    message.Key, 
                    message.Value
                );
                
                await ProcessMessageAsync(message);
            },
            "my-consumer-group",
            cancellationToken
        );
    }
    
    private Task ProcessMessageAsync(IMessage message)
    {
        // Process message

        return Task.CompletedTask;
    }
}
```

#### üìå Background Service for Continuous Consumption

Create a background service to continuously consume messages:

```csharp
public class KafkaConsumerBackgroundService(ISubscriber subscriber, ILogger<KafkaConsumerBackgroundService> logger) : BackgroundService
{
    private readonly ISubscriber _subscriber = subscriber;
    private readonly ILogger<KafkaConsumerBackgroundService> _logger = logger;
    
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        try
        {
            await _subscriber.SubscribeManyAsync(
                new[] { "topic1", "topic2", "topic3" },
                async message =>
                {
                    _logger.LogInformation(
                        "Message received: Topic={Topic}, Key={Key}",
                        message.Topic,
                        message.Key
                    );
                    
                    // Process message
                    await ProcessMessageAsync(message);
                },
                "multi-topic-consumer-group",
                stoppingToken
            );
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error in Kafka consumer service");
        }
    }
    
    private Task ProcessMessageAsync(IMessage message)
    {
        // Process message

        return Task.CompletedTask;
    }
}

// Register the background service
services.AddHostedService<KafkaConsumerBackgroundService>();
```

### 5Ô∏è‚É£ Advanced Configuration

#### üìå Configure Publisher Settings

```csharp
services.AddKafka(Configuration.GetSection("Kafka"))
    .ConfigurePublisher(options => 
    {
        // Configure publisher-specific settings
    })
    .WithAdvancedProducerConfig(config => 
    {
        config.MessageTimeoutMs = 10000;
        config.RequestTimeoutMs = 5000;
        config.Acks = Acks.All;
    })
    .AddPublisher();
```

#### üìå Configure Subscriber Settings

```csharp
services.AddKafka(Configuration.GetSection("Kafka"))
    .ConfigureSubscriber(options => 
    {
        options.CommitEmptyMessages = true;
        // Configure other subscriber-specific settings
    })
    .WithAdvancedConsumerConfig(config => 
    {
        config.AutoOffsetReset = AutoOffsetReset.Earliest;
        config.EnableAutoCommit = false;
        config.MaxPollIntervalMs = 300000;
    })
    .AddSingletonSubscriber();
```

## üöÄ Complete Example: ASP.NET Core Web API with Kafka Integration: [here](https://github.com/AnastasKosstow/sharp-nest/tree/main/samples/kafka/src/SharpNest.Samples.Kafka)

# SharpNest.Kafka Documentation

## üìã Available Options

### KafkaSettings

| Property | Description | Default |
|----------|-------------|---------|
| `BootstrapServers` | Comma-separated list of Kafka broker addresses | `localhost:9092` |
| `DefaultGroup` | Default consumer group ID | `default-group` |
| `Partitions` | Number of partitions for new topics | `1` |
| `ReplicationFactor` | Replication factor for new topics | `1` |
| `Security` | Security settings object | `null` |
| `Subscriber` | Subscriber-specific settings | `new KafkaSubscriberSettings()` |
| `Publisher` | Publisher-specific settings | `new KafkaPublisherSettings()` |

### KafkaSubscriberSettings

| Property | Description | Default |
|----------|-------------|---------|
| `AutoOffsetReset` | Offset reset behavior (earliest, latest, error) | `earliest` |
| `EnableAutoCommit` | Whether to enable auto-commit of offsets | `true` |
| `CommitEmptyMessages` | Whether to commit empty messages | `false` |
| `AutoCommitIntervalMs` | Auto-commit interval in milliseconds | `5000` |
| `SessionTimeoutMs` | Session timeout in milliseconds | `30000` |
| `MaxPollIntervalMs` | Maximum poll interval in milliseconds | `300000` |
| `MaxPartitionFetchBytes` | Number of messages to request in each fetch | `1048576` |

### KafkaPublisherSettings

| Property | Description | Default |
|----------|-------------|---------|
| `Acks` | Required acknowledgments (0, 1, all) | `all` |
| `MessageTimeoutMs` | Message timeout in milliseconds | `30000` |
| `CompressionType` | Compression type (none, gzip, snappy, lz4, zstd) | `none` |
| `BatchSize` | Maximum size of a batch in bytes | `16384` |
| `LingerMs` | Linger time in milliseconds | `5` |
| `MaxInFlight` | Maximum number of in-flight requests | `5` |

### KafkaSecuritySettings

| Property | Description | Default |
|----------|-------------|---------|
| `Protocol` | Security protocol | `SecurityProtocol.Plaintext` |
| `SaslMechanism` | SASL mechanism | `SaslMechanism.Plain` |
| `Username` | SASL username | `null` |
| `Password` | SASL password | `null` |
| `SslCaLocation` | SSL CA certificate location | Not set in class definition |
| `SslCertificateLocation` | SSL certificate location | Not set in class definition |
| `SslKeyLocation` | SSL key location | Not set in class definition |

## üîí Secure Kafka Connections

SharpNest.Kafka supports secure connections to Kafka brokers:

```cs
services.AddKafka(options => 
{
    options.BootstrapServers = "kafka-broker:9093";
    options.Security = new KafkaSecuritySettings
    {
        Protocol = SecurityProtocol.Ssl,
        SslCaLocation = "/path/to/ca.pem",
        SslCertificateLocation = "/path/to/certificate.pem",
        SslKeyLocation = "/path/to/key.pem"
    };
})
.AddPublisher()
.AddSingletonSubscriber();
```

Or in `appsettings.json`:

```json
{
  "Kafka": {
    "BootstrapServers": "kafka-broker:9093",
    "Security": {
      "Protocol": "Ssl",
      "Username": "usr",
      "Password": "pswrd",
      "SslCaLocation": "/path/to/ca.pem",
      "SslCertificateLocation": "/path/to/certificate.pem",
      "SslKeyLocation": "/path/to/key.pem"
    }
  }
}
```

**Note:** The SSL certificate properties (`SslCaLocation`, `SslCertificateLocation`, `SslKeyLocation`) are referenced in the examples but appear to be handled differently in your current KafkaSecuritySettings class definition. You may need to update your class to include these properties if they're needed for SSL connections.
```

## üìú Additional Notes

- SharpNest.Kafka automatically creates topics if they don't exist when subscribing
- The library handles proper disposal of resources to prevent memory leaks
- Thread safety is ensured through semaphore locks for shared resources
- Serialization is handled by the library, with default SystemTextJsonSerializer support
- Custom serializers can be registered if needed
